# -*- coding: utf-8 -*-
"""rembTotal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DOYN4y5pLNi3iLnqhbOCyMuqzDZV2bJs
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest

from google.colab import drive

drive.mount('/content/drive')

rembouresement = pd.read_csv("/content/drive/MyDrive/rembouresement.csv")

rembouresement

df=pd.read_excel("/content/drive/MyDrive/remb_agr.xlsx")

df.to_csv ("rem_agr.csv", index = None,header=True)

agricole= pd.read_csv("/content/rem_agr.csv")

df.info()

df.describe()

#voir les valeurs manquantes
agricole.info()

#concatenation de deux dataset
dff=pd.concat([agricole,rembouresement],axis=0)
dff

"""# **visualisation**"""

# Commented out IPython magic to ensure Python compatibility.

import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
labels=dff.TYPE_ENG.value_counts().index
colors=["purple","pink"]
sizes=dff.TYPE_ENG.value_counts().values
plt.figure(figsize=(5,5))
plt.pie(sizes,labels=labels,colors=colors,autopct="%1.1f%%")
plt.title("TYPE_ENG ",color="saddlebrown",fontsize=10)

"""visulaisation de nombre de chaque produit"""

dff['COD_PRD_PRD'].value_counts().head(30).plot(kind='barh', figsize=(10,10))

"""visualisation de remboursement en fonction des termes"""

sns.set(style="ticks")
plt.figure(figsize=(9,5))
total = float(len(dff))
ax = sns.countplot(x="TERME", hue="TERME", data=dff)
plt.title('Terme de remboursement', fontsize=20)
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax.annotate(percentage, (x, y),ha='center')
plt.show()

cityPerc = dff[["NAT_RESS", "AGENCE"]].groupby(['NAT_RESS'],as_index=False).mean()
sns.barplot(x='NAT_RESS', y='AGENCE', data=cityPerc)

data=dff.drop(['DATE_ECHEANCE','DATE_REMBOURSEMENT','LIB_OPERATION','REMB_INTINT','INTRET','DAT_ECH_ECHCD','DAT_REMB_RMBINV','REMB_INTCONV','LIB_OPER','ACTIVITE','NUM_TR','CREANCE','CODE_FOND','TYP_FOND','TYPE_ENG','NAT_RESS','NUM_DEB','CODE_SPEC','CLASSE','SCLAS_SEGMENT','TERME'],axis=1)

data.info()

data['CREDIT'].fillna(data['CREDIT'].median(),inplace=True)
data['NUM_CRED'].fillna(data['NUM_CRED'].median(),inplace=True)

dataset=pd.get_dummies(data,drop_first=True)
dataset

#description des colonnes
dataset.describe()

dataset['REMBtotal'] = dataset['REMBECHOIRINT'] +dataset['REMBPPRINCIPAL']

dataset.info()

labell=dataset['REMBPPRINCIPAL']
datasett=dataset.drop(['REMBPPRINCIPAL'],axis=1)

from sklearn.model_selection import train_test_split
X_train,X_test,train_label,test_label=train_test_split(datasett,labell,test_size=0.33,random_state=0)

X_train.shape

test_label.shape

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Create a Random Forest regression model
rf = RandomForestRegressor(n_estimators=2, random_state=40)

rf.fit(X_train,train_label)

# Make predictions on the test set
y_pred = rf.predict(X_test)

# Evaluate the model
mse=mean_squared_error(test_label,y_pred)
import math
print('RMSE', math.sqrt(mse))
from sklearn.metrics import explained_variance_score
EV=explained_variance_score(test_label,y_pred)
print("Explained variance %f" %(EV))
def mae(y_true, predictions):
    y_true, predictions = np.array(y_true), np.array(predictions)
    return np.mean(np.abs(y_true - predictions))
print("MAE:",mae(test_label,y_pred))

import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
# Créer un jeu de données LightGBM
train_data = lgb.Dataset(X_train, label=train_label)
# Définir les paramètres du modèle
params = {
    'objective': 'regression',  # Objectif de régression
    'metric': 'rmse',  # Métrique d'évaluation (RMSE)
    'num_leaves': 60,  # Nombre maximum de feuilles dans un arbre
    'learning_rate': 0.1,  # Taux d'apprentissage
    'feature_fraction': 0.8,  # Fraction de fonctionnalités à utiliser à chaque étape de l'arbre
    'bagging_fraction': 0.8,  # Fraction d'échantillons à utiliser pour chaque arbre
    'bagging_freq': 5,  # Fréquence d'utilisation de l'échantillonnage bagging
    'verbose': 0  # Affichage des messages
}

# Entraîner le modèle
model = lgb.train(params, train_data)

# Faire des prédictions sur l'ensemble de test
y_pred = model.predict(X_test)

# Évaluer les performances avec la métrique RMSE
rmse = mean_squared_error(test_label, y_pred, squared=False)
print('RMSE:', rmse)
from sklearn.metrics import explained_variance_score
EV=explained_variance_score(test_label,y_pred)
print("Explained variance %f" %(EV))
def mae(y_true, predictions):
    y_true, predictions = np.array(y_true), np.array(predictions)
    return np.mean(np.abs(y_true - predictions))
print("MAE:",mae(test_label,y_pred))

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
# Créer un jeu de données DMatrix pour XGBoost
dtrain = xgb.DMatrix(X_train, label=train_label)
dtest = xgb.DMatrix(X_test, label=test_label)

# Définir les paramètres du modèle
params = {
    'objective': 'reg:squarederror',  # Objectif de régression
    'eval_metric': 'rmse',  # Métrique d'évaluation (RMSE)
    'max_depth': 15,  # Profondeur maximale de l'arbre
    'learning_rate': 0.1,  # Taux d'apprentissage
    'subsample': 0.9,  # Fraction d'échantillons à utiliser pour chaque arbre
    'colsample_bytree': 0.8,  # Fraction de fonctionnalités à utiliser à chaque étape de l'arbre
    'verbosity': 0  # Affichage des messages
}

# Entraîner le modèle
num_rounds = 29 # Nombre d'itérations d'entraînement (boosting rounds)
model = xgb.train(params, dtrain, num_boost_round=num_rounds)

# Faire des prédictions sur l'ensemble de test
y_pred = model.predict(dtest)

# Évaluer les performances avec la métrique RMSE
rmse = mean_squared_error(test_label,y_pred, squared=False)
print('RMSE:', rmse)
from sklearn.metrics import explained_variance_score
EV=explained_variance_score(test_label,y_pred)
print("Explained variance %f" %(EV))
def mae(y_true, predictions):
    y_true, predictions = np.array(y_true), np.array(predictions)
    return np.mean(np.abs(y_true - predictions))
print("MAE:",mae(test_label,y_pred))

file_path = "/content/drive/MyDrive/saved.h5"
model.save_model(file_path)

from google.colab import files
files.download(file_path)

model.save_model('/content/drive/MyDrive/saved.h5')

model.save_model('model_file_name.model')

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Créer un modèle d'arbre de décision
model = DecisionTreeRegressor(max_depth=2)  # Définir la profondeur maximale de l'arbre

# Entraîner le modèle
model.fit(X_train, train_label)

# Faire des prédictions sur l'ensemble de test
y_pred = model.predict(X_test)

# Évaluer les performances avec la métrique RMSE
rmse = mean_squared_error(test_label, y_pred, squared=False)
print('RMSE:', rmse)
from sklearn.metrics import explained_variance_score
EV=explained_variance_score(test_label,y_pred)
print("Explained variance %f" %(EV))
def mae(y_true, predictions):
    y_true, predictions = np.array(y_true), np.array(predictions)
    return np.mean(np.abs(y_true - predictions))
print("MAE:",mae(test_label,y_pred))